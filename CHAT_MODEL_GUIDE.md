# Chatç”¨LLMãƒ¢ãƒ‡ãƒ«é¸æŠã‚¬ã‚¤ãƒ‰

## ğŸ¤” å•é¡Œ: TinyLlamaã§ã®æ—¥æœ¬èªå¿œç­”ãŒä¸è‡ªç„¶

TinyLlama-1.1B-Chat-v1.0ã¯è‹±èªãƒ¡ã‚¤ãƒ³ã®ãƒ¢ãƒ‡ãƒ«ã®ãŸã‚ã€æ—¥æœ¬èªã§ã®ä¼šè©±ãŒä¸è‡ªç„¶ã«ãªã‚Šã¾ã™ã€‚

### ç—‡çŠ¶
- ã€Œã“ã‚“ã«ã¡ã¯ã€â†’ æ„å‘³ä¸æ˜ãªå¿œç­”
- æ–‡æ³•ãŒãŠã‹ã—ã„
- ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ç†è§£ã—ã¦ã„ãªã„

## âœ… è§£æ±ºç­–: æ—¥æœ¬èªå¯¾å¿œLLMãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨

#### æ¨å¥¨ãƒ¢ãƒ‡ãƒ«

| ãƒ¢ãƒ‡ãƒ« | ã‚µã‚¤ã‚º | ç‰¹å¾´ | æ¨å¥¨åº¦ |
|--------|--------|------|--------|
| **rinna/japanese-gpt-neox-small** | 3.6B | æ—¥æœ¬èªç‰¹åŒ–ã€ä¼šè©±å¯¾å¿œ | â­â­â­â­â­ |
| **cyberagent/open-calm-small** | 1.4B | æ—¥æœ¬èªã€è»½é‡ | â­â­â­â­ |
| **rinna/japanese-gpt-1b** | 1.4B | æ—¥æœ¬èªã€ãƒãƒ©ãƒ³ã‚¹è‰¯ã„ | â­â­â­â­ |
| **stabilityai/japanese-stablelm-base-alpha-7b** | 7B | é«˜å“è³ªï¼ˆè¦ãƒ¡ãƒ¢ãƒªï¼‰ | â­â­â­ |

#### å®Ÿè£…æ–¹æ³•

**1. main.pyã‚’ç·¨é›†**

```python
# main.py ã® get_chat_service() é–¢æ•°ã‚’ä¿®æ­£

def get_chat_service():
    global chat_service

    if chat_service is None:
        with chat_service_lock:
            if chat_service is None:
                # æ—¥æœ¬èªå¯¾å¿œãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
                chat_service = ChatService(
                    model_name="rinna/japanese-gpt-neox-small"
                )
                logger.info("Chat service initialized with Japanese LLM")

    return chat_service
```

**2. chat_service.pyã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’èª¿æ•´**

æ—¥æœ¬èªãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã£ã¦ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãŒç•°ãªã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚

```python
def _format_prompt(self, messages: List[Dict[str, str]], system_prompt: Optional[str] = None) -> str:
    """ãƒ¢ãƒ‡ãƒ«ã«å¿œã˜ã¦ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’å¤‰æ›´"""

    # rinnaãƒ¢ãƒ‡ãƒ«ã®å ´åˆ
    if "rinna" in self.model_name.lower():
        # rinnaãƒ¢ãƒ‡ãƒ«ç”¨ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        formatted = []
        if system_prompt:
            formatted.append(f"ã‚·ã‚¹ãƒ†ãƒ : {system_prompt}\n")

        for msg in messages:
            if msg["role"] == "user":
                formatted.append(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼: {msg['content']}\n")
            elif msg["role"] == "assistant":
                formatted.append(f"ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ: {msg['content']}\n")

        formatted.append("ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ: ")
        return "".join(formatted)

    # TinyLlamaç­‰ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
    else:
        # æ—¢å­˜ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        ...
```

**3. åˆå›å®Ÿè¡Œæ™‚**

ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã¨å¤‰æ›ã«æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ï¼ˆ5-15åˆ†ç¨‹åº¦ï¼‰ã€‚

```bash
# ã‚µãƒ¼ãƒãƒ¼èµ·å‹•
python main.py

# åˆå›ã¯ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
# INFO: Downloading model: rinna/japanese-gpt-neox-small
# INFO: Converting to OpenVINO format...
# INFO: Model loaded successfully
```

### ã‚ªãƒ—ã‚·ãƒ§ãƒ³2: ç¿»è¨³ã‚’çµ„ã¿åˆã‚ã›ã‚‹

æ—¥æœ¬èªå…¥åŠ›ã‚’è‹±èªã«ç¿»è¨³ â†’ TinyLlamaã§å‡¦ç† â†’ æ—¥æœ¬èªã«ç¿»è¨³

**å®Ÿè£…ä¾‹**:

```python
# chat_service.py ã«è¿½åŠ 

def chat_with_translation(self, message: str, session_id: Optional[str] = None):
    """æ—¥æœ¬èªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç¿»è¨³ã—ã¦ã‹ã‚‰å‡¦ç†"""
    from translation_service import TranslationService

    translator = TranslationService()

    # 1. æ—¥æœ¬èªâ†’è‹±èª
    english_message = translator.translate(message, target_lang="en", source_lang="ja")["translated_text"]

    # 2. è‹±èªã§ãƒãƒ£ãƒƒãƒˆ
    response = self.chat(english_message, session_id)

    # 3. è‹±èªâ†’æ—¥æœ¬èª
    japanese_response = translator.translate(response["response"], target_lang="ja", source_lang="en")["translated_text"]

    response["response"] = japanese_response
    return response
```

## ğŸš€ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

```bash
# 1. main.py ã‚’ç·¨é›†ï¼ˆä¸Šè¨˜å‚ç…§ï¼‰
vim main.py

# 2. ã‚µãƒ¼ãƒãƒ¼èµ·å‹•ï¼ˆåˆå›ã¯ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«æ™‚é–“ãŒã‹ã‹ã‚‹ï¼‰
python main.py

# 3. ãƒ†ã‚¹ãƒˆ
curl -X POST http://localhost:8000/api/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "ã“ã‚“ã«ã¡ã¯"}'
```

## ğŸ“Š æ¯”è¼ƒè¡¨

| æ–¹å¼ | å“è³ª | é€Ÿåº¦ | ãƒ¡ãƒ¢ãƒª | ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ— |
|------|------|------|--------|-------------|
| TinyLlama (è‹±èª) | â­ | â­â­â­â­ | 2GB | ä¸­ |
| æ—¥æœ¬èªLLM (1-2B) | â­â­â­â­ | â­â­â­ | 4-6GB | ä¸­ |
| æ—¥æœ¬èªLLM (7B) | â­â­â­â­â­ | â­â­ | 10-14GB | é•· |
| ç¿»è¨³ä½µç”¨ | â­â­â­ | â­â­ | 4GB | ä¸­ |

## ğŸ”§ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ãƒ¡ãƒ¢ãƒªä¸è¶³

```python
# ã‚ˆã‚Šå°ã•ã„ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
chat_service = ChatService(
    model_name="cyberagent/open-calm-small"  # 1.4B
)
```

### ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒé…ã„

```bash
# Hugging Face CLIã§äº‹å‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
pip install huggingface-hub
huggingface-cli download rinna/japanese-gpt-neox-small
```

### ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„

```python
# ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ç¢ºèª
chat_service = ChatService(
    model_name="rinna/japanese-gpt-neox-small",
    cache_dir="./models/chat_llm"  # ç¢ºèª
)
```

## ğŸ“š å‚è€ƒãƒªãƒ³ã‚¯

- [rinna/japanese-gpt-neox-small](https://huggingface.co/rinna/japanese-gpt-neox-small)
- [CyberAgent/open-calm-small](https://huggingface.co/cyberagent/open-calm-small)
- [Stability AI Japanese Models](https://huggingface.co/stabilityai)
- [OpenVINO Model Optimization](https://docs.openvino.ai/latest/index.html)
